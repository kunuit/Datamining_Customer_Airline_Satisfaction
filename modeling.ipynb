{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vuZNcmIG6X02",
        "R490KiXe6X03",
        "sNX2MpU96X08"
      ],
      "toc_visible": true,
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunuit/Datamining_Customer_Airline_Satisfaction/blob/master/modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iojQ0ODC6X0i"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import datetime as dt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Models from Scikit-Learn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Model Evaluations\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbKvj-FM6ms0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1tf08X0G6X0t"
      },
      "source": [
        "## MODELING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNOyL5xh6X0t"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/public subject/olap/cleaned_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmp8BRbi6X0u"
      },
      "source": [
        "# Create X (Features Matrix)\n",
        "X = df.drop(\"satisfaction\", axis = 1)\n",
        "# Create y (labels)\n",
        "y = df[\"satisfaction\"]\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV7paLm86X0v"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train and test sets\n",
        "np.random.seed(44)\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Emdgtcr26X0v"
      },
      "source": [
        "We're going to try _three_ different machine learning models:\n",
        "\n",
        "1. Logistic Regression\n",
        "2. K-Nearest Neighbors\n",
        "3. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nTSkrt6X0w"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Models from Scikit-Learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Model Evaluations\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, f1_score, roc_curve, plot_roc_curve\n",
        "\n",
        "\n",
        "# Put models in a dictionary\n",
        "models = {'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "          'KNN': KNeighborsClassifier(),\n",
        "          'Random Forest': RandomForestClassifier()}\n",
        "\n",
        "# Create a function to fit and score models\n",
        "def fit_and_score(models, Xtrain, Xtest, ytrain, ytest):\n",
        "    \"\"\"\n",
        "    Fits and evaluates given machine learning models.\n",
        "    models: a dict of different Scikit-Learn machine learning models\n",
        "    Xtrain: training data (no labels)\n",
        "    Xtest: testing data (no labels)\n",
        "    ytrain: training labels\n",
        "    ytest: test labels\n",
        "    \"\"\"\n",
        "    # Set random seed\n",
        "    np.random.seed(44)\n",
        "    # Make a dictionary to keep model scores\n",
        "    model_scores = {}\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the data\n",
        "        model.fit(Xtrain, ytrain)\n",
        "        # evaluate model and append score\n",
        "        model_scores[name] = model.score(Xtest, ytest)\n",
        "    return model_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTFrYGJ6X0x"
      },
      "source": [
        "model_scores = fit_and_score(models=models,\n",
        "                             Xtrain=Xtrain,\n",
        "                             Xtest=Xtest,\n",
        "                             ytrain=ytrain,\n",
        "                             ytest=ytest)\n",
        "model_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JvOIqMy66X0x"
      },
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyChU5Xo6X0x"
      },
      "source": [
        "model_compare = pd.DataFrame(model_scores, index=['accuracy'])\n",
        "model_compare.T.plot.bar()\n",
        "plt.xticks(rotation=1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vWSlRiHJ6X0y"
      },
      "source": [
        "How to improve the baseline metrics?\n",
        "\n",
        "| classification | regression                     |\n",
        "| ---------------| -------------------------------|\n",
        "| **accuracy**   | **r^2**                        |\n",
        "| precision      | mean absolute error            |\n",
        "| recall         | maen squared error (MSE)       |\n",
        "| f1             | root mean squared error (RMSE) |\n",
        "\n",
        "Ideas:\n",
        "\n",
        "* hyperparameter tuning\n",
        "* feature importance\n",
        "* confusion matrix\n",
        "* precision\n",
        "* recall\n",
        "* f1 score\n",
        "* classification report\n",
        "* roc curve\n",
        "* area under the curve (AUC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SyeNjp7i6X0y"
      },
      "source": [
        "## Hyperparameter Tuning (by Hand)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejg0DB_f6X0z"
      },
      "source": [
        "# Tune KNN\n",
        "np.random.seed(44)\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "# Create a list of different values for n_neighbors\n",
        "neighbors = range(1,21)\n",
        "\n",
        "# Setup KNN instance\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Loop through different n_neighbors\n",
        "for i in neighbors:\n",
        "    knn.set_params(n_neighbors=i)\n",
        "\n",
        "    # Fit algorithm\n",
        "    knn.fit(Xtrain, ytrain)\n",
        "\n",
        "    # Update training scores list\n",
        "    train_scores.append(knn.score(Xtrain, ytrain))\n",
        "\n",
        "    # Update test_scores list\n",
        "    test_scores.append(knn.score(Xtest, ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhWyou5G6X0z"
      },
      "source": [
        "train_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtwvmy6N6X0z"
      },
      "source": [
        "test_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqmKF8QM6X00"
      },
      "source": [
        "plt.plot(neighbors, train_scores, label='Train Scores')\n",
        "plt.plot(neighbors, test_scores, label='Test Scores')\n",
        "plt.xticks(np.arange(1,21,1))\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Model Score')\n",
        "plt.legend();\n",
        "\n",
        "print(f\"Maximum KNN score on test data: {max(test_scores)*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HZzlXb-W6X00"
      },
      "source": [
        "## Hyperparamter Tuning with RandomizedSearchCV\n",
        "\n",
        "We're going to tune:\n",
        "* LogisticRegression\n",
        "* RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ztft6N3t6X00"
      },
      "source": [
        "### Tuning Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIFglk1J6X00"
      },
      "source": [
        "# Create a hyperparameter grid for LogisticRegression\n",
        "log_reg_grid = {'C': np.logspace(-4, 4, 20),\n",
        "                'penalty': ['l1', 'l2'],\n",
        "                'solver': ['liblinear']}\n",
        "\n",
        "# Create a hyperparameter grid for RandomClassifier\n",
        "rf_grid = {'n_estimators': np.arange(10, 1000, 50),\n",
        "           'max_depth': [None, 3, 5, 10],\n",
        "           'min_samples_split': np.arange(2, 20, 2),\n",
        "           'min_samples_leaf': np.arange(1, 20, 2)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBw7Oh-b6X01"
      },
      "source": [
        "# Tune Logistic Regression\n",
        "\n",
        "np.random.seed(44)\n",
        "\n",
        "# Setup random hyperparameter search for LogisticRegression\n",
        "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
        "                                param_distributions=log_reg_grid,\n",
        "                                cv=5,\n",
        "                                n_iter=20,\n",
        "                                verbose=True)\n",
        "\n",
        "# Fit random hyperparameter search model for Logistic Regression\n",
        "rs_log_reg.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUA7IG846X02"
      },
      "source": [
        "rs_log_reg.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xON6VdIM6X02"
      },
      "source": [
        "rs_log_reg.score(Xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vuZNcmIG6X02"
      },
      "source": [
        "### Tuning Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm71vFQs6X02"
      },
      "source": [
        "# Tune Random Forest\n",
        "\n",
        "np.random.seed(44)\n",
        "\n",
        "# Setup random hyperparameter search for LogisticRegression\n",
        "rs_rf_reg = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                               param_distributions=rf_grid,\n",
        "                               cv=5,\n",
        "                               n_iter=10,\n",
        "                               verbose=True)\n",
        "\n",
        "# Fit random hyperparameter search model for Logistic Regression\n",
        "rs_rf_reg.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTvHrPTQ6X03"
      },
      "source": [
        "rs_rf_reg.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJdMUz3M6X03"
      },
      "source": [
        "# Evaluate the tuned model\n",
        "rs_rf_reg.score(Xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "R490KiXe6X03"
      },
      "source": [
        "### Compare hypertuned models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bu5hBJ6X03"
      },
      "source": [
        "tuned_model_scores = fit_and_score(models={'RS Logistic Regression': rs_log_reg,\n",
        "                                           'RS Random Forest': rs_rf_reg},\n",
        "                                   Xtrain=Xtrain,\n",
        "                                   Xtest=Xtest,\n",
        "                                   ytrain=ytrain,\n",
        "                                   ytest=ytest)\n",
        "tuned_model_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQLxnuY06X04"
      },
      "source": [
        "tuned_model_compare = pd.DataFrame(tuned_model_scores, index=['accuracy'])\n",
        "tuned_model_compare.T.plot.bar()\n",
        "plt.xticks(rotation=1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "BsNk07J16X04"
      },
      "source": [
        "## Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "Since our Logisti Regression model provides the best scores so far, we'll try to improve the model further using GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDllzQOB6X04"
      },
      "source": [
        "# Create a hyperparameter grid for LogisticRegression with liblinear solver\n",
        "log_reg_libnear_grid = {'C': np.logspace(-4, 4, 30),\n",
        "                'penalty': ['l1', 'l2'],\n",
        "                'solver': ['liblinear']}\n",
        "\n",
        "# Setup grid hyperparameter search for LogisticRegression\n",
        "gs_log_reg_liblinear = GridSearchCV(LogisticRegression(),\n",
        "                          param_grid=log_reg_grid,\n",
        "                          cv=5,\n",
        "                          verbose=True)\n",
        "\n",
        "# Fit model\n",
        "gs_log_reg_liblinear.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soogsw9G6X04"
      },
      "source": [
        "# Check best parameters\n",
        "gs_log_reg_liblinear.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NctFFNuj6X05"
      },
      "source": [
        "# Evaluate grid search Logistic Regression model\n",
        "gs_log_reg_liblinear.score(Xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evjGlL9B6X05"
      },
      "source": [
        "# Create a hyperparameter grid for LogisticRegression\n",
        "log_reg_libnear_grid = {'C': np.logspace(-4, 4, 30),\n",
        "                'penalty': ['l1', 'l2'],\n",
        "                'solver': ['liblinear']}\n",
        "\n",
        "# Setup grid hyperparameter search for LogisticRegression\n",
        "gs_log_reg_liblinear = GridSearchCV(LogisticRegression(),\n",
        "                          param_grid=log_reg_grid,\n",
        "                          cv=5,\n",
        "                          verbose=True)\n",
        "\n",
        "# Fit model\n",
        "gs_log_reg_liblinear.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuSbNZep6X05"
      },
      "source": [
        "# Create a hyperparameter grid for LogisticRegression with lbfgs solver\n",
        "log_reg_libnear_grid = {'C': np.logspace(-4, 4, 30),\n",
        "                'penalty': [None, 'l2'],\n",
        "                'solver': ['lbfgs']}\n",
        "\n",
        "# Setup grid hyperparameter search for LogisticRegression\n",
        "gs_log_reg_lbfgs = GridSearchCV(LogisticRegression(),\n",
        "                          param_grid=log_reg_grid,\n",
        "                          cv=5,\n",
        "                          verbose=True)\n",
        "\n",
        "# Fit model\n",
        "gs_log_reg_lbfgs.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZszafAC6X06"
      },
      "source": [
        "gs_log_reg_lbfgs.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws-YH91K6X06"
      },
      "source": [
        "gs_log_reg_lbfgs.score(Xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObL9JVL6X06"
      },
      "source": [
        "rs_model_scores = fit_and_score(models={'Baseline Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "                                        'RS Log. Regression': rs_log_reg,\n",
        "                                        'Grid Search with liblinear': gs_log_reg_liblinear,\n",
        "                                        'Grid Search with lbfgs': gs_log_reg_lbfgs},\n",
        "                                   Xtrain=Xtrain,\n",
        "                                   Xtest=Xtest,\n",
        "                                   ytrain=ytrain,\n",
        "                                   ytest=ytest)\n",
        "rs_model_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ge-mvuT6X06"
      },
      "source": [
        "rs_model_compare = pd.DataFrame(rs_model_scores, index=['accuracy'])\n",
        "rs_model_compare.T.plot.bar();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Akw2WKvF6X07"
      },
      "source": [
        "## Evaluating tuned machine learning classifier, beyond accuracy\n",
        "\n",
        "* ROC curve, AUC curve\n",
        "* Confusion matrix\n",
        "* Classificatoin report\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "... with cross-validation where possible.\n",
        "\n",
        "To make comparions and evaluate our trained model, we need to make predictions first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5uUre24j6X07"
      },
      "source": [
        "### ROC curve and AUC metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHhDP7Md6X07"
      },
      "source": [
        "# Make predictions with best tuned model on test/train-split data-\n",
        "ypreds = rs_log_reg.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVPjhKI06X08"
      },
      "source": [
        "# Plot ROC curve and calculate AUC metric\n",
        "plot_roc_curve(rs_log_reg, Xtest, ytest);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2-UmCEA66X08"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR77hdol6X08"
      },
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(ytest, ypreds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uhDxKJV6X08"
      },
      "source": [
        "# Plot confusion matrix\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(cm.T, annot=True, fmt='d', annot_kws={\"size\": 16}, square=True, cbar=False)\n",
        "plt.xlabel('actual')\n",
        "plt.ylabel('predictions');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sNX2MpU96X08"
      },
      "source": [
        "### Classifiction Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF1qcVEX6X09"
      },
      "source": [
        "# Classification Report on train/test-split data\n",
        "print(classification_report(ytest, ypreds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nRwv_VFv6X09"
      },
      "source": [
        "### Cross-validated evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4YFXPlJ6X09"
      },
      "source": [
        "# Check best hyperparameters\n",
        "rs_log_reg.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyWYeOu16X09"
      },
      "source": [
        "# Create a new classifier with best parameters\n",
        "clf = LogisticRegression(C=29.763514416313132,\n",
        "                         solver='liblinear',\n",
        "                         penalty='l1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSU60X46X09"
      },
      "source": [
        "def average_metric(clf, X, y, scoring):\n",
        "    \"\"\"\n",
        "    Returns the average score on each scoring metric, rounded to 2 decimals.\n",
        "    clf: scikit-learn classification\n",
        "    X: features (no labels)\n",
        "    y: labels\n",
        "    scoring: scoring metric\n",
        "    \"\"\"\n",
        "    return round((np.mean(cross_val_score(clf, X, y, cv=5, scoring=scoring))), 2)\n",
        "\n",
        "\n",
        "def average_score_on_cross_val_classification(clf, X, y):\n",
        "    \"\"\"\n",
        "    Evaluates a given model/estimator using cross-validation (5 folds)\n",
        "    and returns a dict containing the average (mean) scores\n",
        "    for classification models\n",
        "\n",
        "    clf: scikit-learn classification\n",
        "    X: features (no labels)\n",
        "    y: labels\n",
        "    \"\"\"\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    scores = {metric: average_metric(clf, X, y, metric) for metric in metrics}\n",
        "\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N6gwVZF6X0-"
      },
      "source": [
        "cv_metrics = average_score_on_cross_val_classification(clf, X, y)\n",
        "cv_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImPLYd_k6X0-"
      },
      "source": [
        "# Create visualization\n",
        "cv_metrics_df = pd.DataFrame(cv_metrics, index=[0])\n",
        "\n",
        "cv_metrics_df.T.plot.bar(title='Cross-validated classification metrics',\n",
        "                         legend=False);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnRFMM3T6X0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}